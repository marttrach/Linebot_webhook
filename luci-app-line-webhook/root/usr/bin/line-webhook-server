#!/usr/bin/env python3
# LINE Webhook Server for OpenWrt
# Reads configuration from UCI and handles LINE BOT messages
# Uses Python built-in http.server (no Flask dependency)

import json
import hashlib
import hmac
import base64
import subprocess
import shlex
import logging
import threading
import queue
import ssl
import time
from pathlib import Path
from collections import deque
from http.server import HTTPServer, BaseHTTPRequestHandler

# Log level mapping: è‡´å‘½ > éŒ¯èª¤ > è­¦å‘Š > è³‡è¨Š > é™¤éŒ¯
LOG_LEVELS = {
    'critical': logging.CRITICAL,  # è‡´å‘½
    'error': logging.ERROR,        # éŒ¯èª¤
    'warning': logging.WARNING,    # è­¦å‘Š
    'info': logging.INFO,          # è³‡è¨Š
    'debug': logging.DEBUG,        # é™¤éŒ¯
}


def setup_logging():
    """Configure logging based on UCI config."""
    # Read log level from UCI (must use subprocess directly here)
    log_level_str = 'info'
    try:
        result = subprocess.run(
            ['uci', 'get', 'line_webhook.main.log_level'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            log_level_str = result.stdout.strip().lower()
    except Exception:
        pass

    level = LOG_LEVELS.get(log_level_str, logging.INFO)

    # Configure logging format - more detailed for debug mode
    if level == logging.DEBUG:
        log_format = '%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] %(message)s'
    else:
        log_format = '%(asctime)s - %(levelname)s - %(message)s'

    logging.basicConfig(
        level=level,
        format=log_format,
        force=True  # Override any existing config
    )
    return logging.getLogger(__name__)


# Initialize logger (will be reconfigured in main())
logger = logging.getLogger(__name__)

# Cache to provide simple idempotency for webhookEventId
EVENT_CACHE_LIMIT = 1024
_event_cache = deque()
_event_cache_set = set()
event_queue = queue.Queue()
MAX_EVENT_AGE_MS = 5 * 60 * 1000  # 5 minutes tolerance for replay protection
PROCESSOR_ECHO = 'echo'
PROCESSOR_REMOTE_LLM = 'remote_llm'
PROCESSOR_OPENCLAW = 'openclaw'


def get_uci_config(option, default=''):
    """Read configuration from UCI."""
    try:
        result = subprocess.run(
            ['uci', 'get', f'line_webhook.main.{option}'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except Exception as e:
        logger.error(f"Failed to read UCI config {option}: {e}")
    return default


def build_tls_context(cert_path, key_path):
    """
    Build an SSLContext enforcing TLS 1.2+ and allowed ciphers.
    Raises ValueError on missing files.
    """
    cert_file = Path(cert_path)
    key_file = Path(key_path)
    if not cert_file.exists() or not key_file.exists():
        raise ValueError(f"TLS files missing: cert={cert_file}, key={key_file}")

    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
    # Enforce TLS 1.2+
    context.minimum_version = ssl.TLSVersion.TLSv1_2
    # Recommended cipher suites per rule.md/signature.md
    context.set_ciphers(
        "TLS_AES_256_GCM_SHA384:"
        "TLS_CHACHA20_POLY1305_SHA256:"
        "TLS_AES_128_GCM_SHA256:"
        "TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"
    )
    context.load_cert_chain(certfile=str(cert_file), keyfile=str(key_file))
    # Disable client renegotiation and compression if supported
    try:
        context.options |= ssl.OP_NO_COMPRESSION
    except Exception:
        pass
    return context


def validate_signature(body, signature, channel_secret):
    """Validate LINE webhook signature using raw request body bytes."""
    if not signature or not channel_secret:
        return False
    if isinstance(body, str):
        body = body.encode('utf-8')
    hash_value = hmac.new(
        channel_secret.encode('utf-8'),
        body,
        hashlib.sha256
    ).digest()
    calculated_signature = base64.b64encode(hash_value).decode('utf-8')
    return hmac.compare_digest(signature, calculated_signature)


def is_duplicate_event(event_id):
    """Simple in-memory idempotency check for webhookEventId."""
    if not event_id:
        return False
    if event_id in _event_cache_set:
        return True

    _event_cache.append(event_id)
    _event_cache_set.add(event_id)

    if len(_event_cache) > EVENT_CACHE_LIMIT:
        oldest = _event_cache.popleft()
        _event_cache_set.discard(oldest)

    return False


def is_timestamp_valid(timestamp_ms, max_age_ms=MAX_EVENT_AGE_MS):
    """Validate event timestamp is within acceptable window."""
    if timestamp_ms is None:
        return True  # allow if missing to avoid false negatives
    try:
        ts = int(timestamp_ms)
    except Exception:
        return False
    now_ms = int(time.time() * 1000)
    if ts > now_ms + max_age_ms:
        return False  # too far in the future
    if now_ms - ts > max_age_ms:
        return False  # too old
    return True


def extract_text_from_payload(payload):
    """
    Try to extract a text response from various common LLM API shapes.
    Supports OpenAI-style choices, generic 'reply/output/response' fields,
    or a raw string payload.
    """
    if payload is None:
        return ''
    if isinstance(payload, str):
        return payload.strip()
    try:
        # OpenAI / compatible schema
        choices = payload.get('choices') or []
        if choices:
            choice = choices[0]
            # chat format
            content = (
                choice.get('message', {}).get('content') or
                choice.get('text') or
                ''
            )
            if content:
                return content.strip()
        # Generic fields
        for key in ('reply', 'output', 'response', 'result'):
            if key in payload and isinstance(payload[key], str):
                return payload[key].strip()
    except Exception:
        pass
    return ''



def process_with_remote_llm(text):
    """
    Call a remote LLM HTTP API using Ollama's API.
    Supports both /api/chat and /api/generate endpoints.
    - /api/chat: Sends {"model": "...", "messages": [...]}
    - /api/generate: Sends {"model": "...", "prompt": "..."}
    Handles streaming NDJSON response automatically.
    Authorization: Bearer <remote_api_key> when provided.
    """
    import requests

    url = get_uci_config('remote_api_url', '')
    api_key = get_uci_config('remote_api_key', '')
    model = get_uci_config('remote_api_model', 'llama3')
    timeout_cfg = get_uci_config('remote_api_timeout', '60')
    try:
        timeout = int(timeout_cfg)
    except Exception:
        timeout = 60

    if not url:
        raise ValueError("remote_api_url is empty")

    headers = {'Content-Type': 'application/json'}
    if api_key:
        headers['Authorization'] = f'Bearer {api_key}'

    # Auto-detect endpoint type based on URL path
    if '/api/generate' in url:
        # Ollama /api/generate format
        payload = {
            'model': model,
            'prompt': text
        }
    else:
        # Ollama /api/chat format (default)
        payload = {
            'model': model,
            'messages': [
                {'role': 'user', 'content': text}
            ]
        }

    logger.info("Routing message to remote LLM API: %s (model: %s)", url, model)

    # Use stream=True to handle NDJSON streaming response
    resp = requests.post(url, json=payload, headers=headers, timeout=timeout, stream=True)
    resp.raise_for_status()

    # Parse streaming NDJSON response
    content_parts = []
    for line in resp.iter_lines():
        if line:
            try:
                chunk = json.loads(line.decode('utf-8'))
                # Auto-detect response format:
                # - /api/chat uses: {"message": {"content": "..."}}
                # - /api/generate uses: {"response": "..."}
                content = chunk.get('message', {}).get('content', '') or chunk.get('response', '')
                if content:
                    content_parts.append(content)
                # Check if done
                if chunk.get('done', False):
                    break
            except json.JSONDecodeError:
                logger.debug("Failed to parse NDJSON line: %s", line)
                continue

    reply = ''.join(content_parts).strip()
    if not reply:
        reply = "ï¼ˆremote LLM å›žè¦†ç‚ºç©ºï¼‰"
    return reply


def process_with_openclaw(text):
    """
    Call OpenClaw chat endpoint. Expects POST JSON {message, model?}
    with Authorization: Bearer <token>.
    Supports both regular JSON and streaming NDJSON responses.
    """
    import requests

    url = get_uci_config('openclaw_url', '')
    token = get_uci_config('openclaw_token', '')
    model = get_uci_config('openclaw_model', '')
    timeout_cfg = get_uci_config('openclaw_timeout', '60')
    try:
        timeout = int(timeout_cfg)
    except Exception:
        timeout = 60

    if not url or not token:
        raise ValueError("openclaw_url or openclaw_token is empty")

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}'
    }
    payload = {'message': text}
    if model:
        payload['model'] = model

    logger.info("Routing message to OpenClaw: %s", url)

    # Use stream=True to handle potential streaming NDJSON response
    resp = requests.post(url, json=payload, headers=headers, timeout=timeout, stream=True)
    resp.raise_for_status()

    # Try to detect if response is streaming NDJSON or regular JSON
    content_type = resp.headers.get('Content-Type', '')

    # For streaming responses, parse NDJSON
    if 'text/event-stream' in content_type or 'application/x-ndjson' in content_type:
        content_parts = []
        for line in resp.iter_lines():
            if line:
                try:
                    chunk = json.loads(line.decode('utf-8'))
                    # Try multiple response formats
                    content = (
                        chunk.get('message', {}).get('content', '') or
                        chunk.get('response', '') or
                        chunk.get('text', '') or
                        chunk.get('content', '')
                    )
                    if content:
                        content_parts.append(content)
                    if chunk.get('done', False):
                        break
                except json.JSONDecodeError:
                    continue
        reply = ''.join(content_parts).strip()
    else:
        # Regular JSON response
        reply = extract_text_from_payload(resp.json())
        if not reply:
            reply = resp.text.strip()

    if not reply:
        reply = "ï¼ˆOpenClaw å›žè¦†ç‚ºç©ºï¼‰"
    return reply


def route_message_text(text):
    """Dispatch text to the selected processor and return reply text."""
    processor = get_uci_config('processor', PROCESSOR_ECHO).lower() or PROCESSOR_ECHO
    try:
        if processor == PROCESSOR_REMOTE_LLM:
            return process_with_remote_llm(text)
        if processor == PROCESSOR_OPENCLAW:
            return process_with_openclaw(text)
        # Default: echo
        return text
    except Exception as e:
        logger.error("Processor '%s' failed: %s", processor, e)
        return f"[{processor} error] " + text


def handle_event(event, access_token):
    """Dispatch LINE events."""
    event_type = event.get('type', '')
    logger.info(f"Processing event: {event_type}")

    if event_type == 'message':
        process_message(event, access_token)
    else:
        logger.info(f"Unhandled event type: {event_type}")


def event_worker():
    """Background worker to process events asynchronously."""
    while True:
        item = event_queue.get()
        if item is None:
            break
        event, access_token = item
        try:
            handle_event(event, access_token)
        except Exception as e:
            logger.error(f"Error handling event: {e}")
        finally:
            event_queue.task_done()


def send_reply(reply_token, messages, access_token):
    """Send reply message via LINE API."""
    import requests

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {access_token}'
    }

    data = {
        'replyToken': reply_token,
        'messages': messages
    }

    try:
        response = requests.post(
            'https://api.line.me/v2/bot/message/reply',
            headers=headers,
            json=data,
            timeout=10
        )
        response.raise_for_status()
        logger.info("Reply sent successfully")
        return True
    except Exception as e:
        logger.error(f"Failed to send reply: {e}")
        return False


def send_push_message(user_id, messages, access_token):
    """Send push message to a specific user via LINE API."""
    import requests

    if not user_id:
        logger.error("Cannot send push message: user_id is empty")
        return False

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {access_token}'
    }

    data = {
        'to': user_id,
        'messages': messages
    }

    try:
        response = requests.post(
            'https://api.line.me/v2/bot/message/push',
            headers=headers,
            json=data,
            timeout=10
        )
        response.raise_for_status()
        logger.info(f"Push message sent successfully to {user_id[:8]}...")
        return True
    except Exception as e:
        logger.error(f"Failed to send push message: {e}")
        return False


def format_grafana_alert(payload):
    """
    Format Grafana alert payload into LINE message text.
    Supports both single alert and grouped alerts.
    """
    status = payload.get('status', 'unknown').upper()
    title = payload.get('title', 'Grafana Alert')
    message = payload.get('message', '')
    alerts = payload.get('alerts', [])

    # Status emoji
    status_emoji = 'ðŸ”¥' if status == 'FIRING' else 'âœ…' if status == 'RESOLVED' else 'âš ï¸'

    lines = []
    lines.append(f"{status_emoji} {title}")
    lines.append(f"ç‹€æ…‹: {status}")
    lines.append("")

    # Process individual alerts
    for i, alert in enumerate(alerts[:5], 1):  # Limit to 5 alerts
        alert_status = alert.get('status', 'unknown')
        labels = alert.get('labels', {})
        annotations = alert.get('annotations', {})

        alert_name = labels.get('alertname', f'Alert {i}')
        summary = annotations.get('summary', '')
        description = annotations.get('description', '')

        lines.append(f"ã€{alert_name}ã€‘")
        if summary:
            lines.append(f"  æ‘˜è¦: {summary}")
        if description:
            lines.append(f"  æè¿°: {description[:100]}")

        # Show relevant labels
        for key in ['severity', 'instance', 'job']:
            if key in labels:
                lines.append(f"  {key}: {labels[key]}")
        lines.append("")

    # Truncation notice
    if len(alerts) > 5:
        lines.append(f"... é‚„æœ‰ {len(alerts) - 5} å€‹å‘Šè­¦")

    # Add generator URL if available
    if alerts and alerts[0].get('generatorURL'):
        lines.append(f"\nðŸ”— {alerts[0]['generatorURL']}")

    return '\n'.join(lines)


def mark_as_read(mark_token, access_token):
    """Mark message as read using the v2.1 API."""
    import requests

    if not mark_token:
        return False

    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {access_token}'
    }
    payload = {"markAsReadToken": mark_token}

    try:
        resp = requests.post(
            'https://api.line.me/v2/bot/chat/markAsRead',
            headers=headers,
            json=payload,
            timeout=5
        )
        resp.raise_for_status()
        logger.info("Marked message as read")
        return True
    except Exception as e:
        logger.warning(f"Failed to mark as read: {e}")
        return False


def process_message(event, access_token):
    """
    Process incoming message and generate reply.
    This function can be extended for custom logic.
    """
    message_type = event.get('message', {}).get('type', '')
    reply_token = event.get('replyToken', '')
    mark_token = event.get('message', {}).get('markAsReadToken')

    # Log the sender's user ID (useful for Grafana integration setup)
    source = event.get('source', {})
    user_id = source.get('userId', '')
    if user_id:
        logger.info(f"Message from user: {user_id}")

    if not reply_token:
        return

    # Mark as read when token is provided (2025 Messaging API spec)
    if mark_token:
        mark_as_read(mark_token, access_token)

    if message_type == 'text':
        text = event['message'].get('text', '')
        reply_text = route_message_text(text)
        messages = [{'type': 'text', 'text': reply_text}]
    else:
        messages = [{'type': 'text', 'text': 'Unsupported message type.'}]

    send_reply(reply_token, messages, access_token)


class WebhookHandler(BaseHTTPRequestHandler):
    """HTTP Request Handler for LINE Webhook."""

    def log_message(self, format, *args):
        """Override to use our logger."""
        logger.info("%s - %s" % (self.address_string(), format % args))

    def send_text_response(self, code, message):
        """Send a text response."""
        self.send_response(code)
        self.send_header('Content-Type', 'text/plain; charset=utf-8')
        self.end_headers()
        self.wfile.write(message.encode('utf-8'))

    def send_json_response(self, code, payload=None):
        """Send a JSON response (default empty object)."""
        if payload is None:
            payload = {}
        body = json.dumps(payload).encode('utf-8')
        self.send_response(code)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Content-Length', str(len(body)))
        self.end_headers()
        self.wfile.write(body)

    def do_GET(self):
        """Handle GET requests - health check."""
        if self.path == '/grafana':
            self.send_text_response(200, 'Grafana webhook endpoint is available')
        else:
            self.send_text_response(200, 'LINE Webhook Server is running')

    def do_POST(self):
        """Handle POST requests - webhook events."""
        logger.debug("=" * 60)
        logger.debug("Received POST request")
        logger.debug(f"Request path: {self.path}")
        logger.debug(f"Client address: {self.client_address}")

        # Route to appropriate handler based on path
        if self.path == '/grafana' or self.path.startswith('/grafana?'):
            self.handle_grafana_webhook()
        else:
            self.handle_line_webhook()

    def handle_grafana_webhook(self):
        """Handle Grafana alerting webhook."""
        logger.info("Processing Grafana webhook")

        # Get configuration
        access_token = get_uci_config('access_token')
        grafana_user_id = get_uci_config('grafana_user_id', '')
        grafana_secret = get_uci_config('grafana_secret', '')

        # Validate Bearer token if grafana_secret is configured
        if grafana_secret:
            auth_header = self.headers.get('Authorization', '')
            expected_auth = f'Bearer {grafana_secret}'
            if not auth_header:
                logger.warning("Grafana webhook rejected: missing Authorization header")
                self.send_json_response(401, {"message": "missing Authorization header"})
                return
            if not hmac.compare_digest(auth_header, expected_auth):
                logger.warning("Grafana webhook rejected: invalid token")
                self.send_json_response(403, {"message": "invalid token"})
                return
            logger.debug("Grafana Bearer token validated")
        else:
            logger.warning("Grafana webhook has no secret configured - accepting without auth")

        if not access_token:
            logger.error("Missing access_token in configuration")
            self.send_json_response(500, {"message": "missing access_token"})
            return

        if not grafana_user_id:
            logger.error("Missing grafana_user_id in configuration")
            self.send_json_response(500, {"message": "missing grafana_user_id - set it in LuCI"})
            return

        # Get request body
        content_length = int(self.headers.get('Content-Length', 0))
        raw_body = self.rfile.read(content_length) if content_length > 0 else b''

        try:
            payload = json.loads(raw_body)
            logger.debug(f"Grafana payload: {payload}")

            # Format the alert message
            alert_text = format_grafana_alert(payload)

            # Send to LINE via Push Message
            messages = [{'type': 'text', 'text': alert_text}]
            success = send_push_message(grafana_user_id, messages, access_token)

            if success:
                self.send_json_response(200, {"message": "alert sent to LINE"})
            else:
                self.send_json_response(500, {"message": "failed to send to LINE"})

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Grafana JSON: {e}")
            self.send_json_response(400, {"message": "invalid JSON"})
        except Exception as e:
            logger.error(f"Error processing Grafana webhook: {e}")
            self.send_json_response(500, {"message": "internal error"})

    def handle_line_webhook(self):
        """Handle LINE Messaging API webhook."""
        # Debug: Log all headers
        logger.debug("--- Request Headers ---")
        for header, value in self.headers.items():
            # Mask sensitive headers in logs
            if 'authorization' in header.lower():
                logger.debug(f"  {header}: [MASKED]")
            else:
                logger.debug(f"  {header}: {value}")

        # Get configuration
        access_token = get_uci_config('access_token')
        channel_secret = get_uci_config('channel_secret')

        logger.debug(f"Channel secret length: {len(channel_secret) if channel_secret else 0}")
        logger.debug(f"Access token present: {bool(access_token)}")

        if not access_token or not channel_secret:
            logger.error("Missing access_token or channel_secret in configuration")
            self.send_json_response(500, {"message": "missing configuration"})
            return

        # Get request body
        content_length = int(self.headers.get('Content-Length', 0))
        raw_body = self.rfile.read(content_length) if content_length > 0 else b''

        # Debug: Log raw body details
        logger.debug("--- Request Body ---")
        logger.debug(f"Content-Length header: {content_length}")
        logger.debug(f"Actual body length: {len(raw_body)}")
        logger.debug(f"Raw body (repr): {raw_body!r}")
        try:
            logger.debug(f"Raw body (decoded): {raw_body.decode('utf-8')}")
        except Exception as e:
            logger.debug(f"Failed to decode body as UTF-8: {e}")

        # Get signature
        signature = self.headers.get('X-Line-Signature', '') or self.headers.get('x-line-signature', '')

        logger.debug("--- Signature Validation ---")
        logger.debug(f"Received signature: {signature}")

        # Debug: Calculate and show expected signature
        if channel_secret and raw_body:
            import hashlib as hs
            import hmac as hm
            import base64 as b64
            expected_hash = hm.new(
                channel_secret.encode('utf-8'),
                raw_body,
                hs.sha256
            ).digest()
            expected_sig = b64.b64encode(expected_hash).decode('utf-8')
            logger.debug(f"Calculated signature: {expected_sig}")
            logger.debug(f"Signatures match: {signature == expected_sig}")

        # Validate signature
        if not validate_signature(raw_body, signature, channel_secret):
            logger.warning("Invalid signature - request rejected")
            logger.debug("Signature validation failed. Possible causes:")
            logger.debug("  1. Wrong channel_secret in UCI config")
            logger.debug("  2. Request body modified by proxy/CDN")
            logger.debug("  3. Signature header missing or malformed")
            self.send_json_response(403, {"message": "invalid signature"})
            return

        logger.debug("Signature validation passed")

        # Parse and process events
        try:
            data = json.loads(raw_body)
            events = data.get('events', [])

            # No events is valid for console verification
            if not events:
                self.send_json_response(200, {})
                return

            for event in events:
                if not is_timestamp_valid(event.get('timestamp')):
                    logger.warning("Rejected event due to stale/invalid timestamp")
                    self.send_json_response(400, {"message": "timestamp invalid or too old"})
                    return

                event_id = event.get('webhookEventId')
                if is_duplicate_event(event_id):
                    logger.info(f"Skip duplicate event: {event_id}")
                    continue

                delivery_ctx = event.get('deliveryContext', {})
                if delivery_ctx.get('isRedelivery'):
                    logger.info(f"Redelivery flagged for event: {event_id}")

                # Enqueue for async processing to keep response <2s
                event_queue.put((event, access_token))

            # Early ACK to LINE platform
            self.send_json_response(200, {})

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON: {e}")
            self.send_json_response(400, {"message": "invalid JSON"})
        except Exception as e:
            logger.error(f"Error processing webhook: {e}")
            self.send_json_response(500, {"message": "internal error"})


def main():
    """Main entry point."""
    global logger
    logger = setup_logging()

    log_level = get_uci_config('log_level', 'info')
    logger.info(f"Log level set to: {log_level.upper()}")
    logger.debug("Debug logging is enabled - showing maximum log details")

    port = int(get_uci_config('port', '5000'))
    bind_address = get_uci_config('bind_address', '0.0.0.0')
    use_tls = get_uci_config('use_tls', '0') == '1'
    tls_cert = get_uci_config('tls_cert', '/etc/ssl/line_webhook/server.crt')
    tls_key = get_uci_config('tls_key', '/etc/ssl/line_webhook/server.key')

    server_address = (bind_address, port)
    httpd = HTTPServer(server_address, WebhookHandler)

    if use_tls:
        try:
            tls_ctx = build_tls_context(tls_cert, tls_key)
            httpd.socket = tls_ctx.wrap_socket(httpd.socket, server_side=True)
            logger.info(
                "TLS enabled (>=TLS1.2) with cert=%s key=%s",
                tls_cert,
                tls_key,
            )
        except Exception as e:
            logger.error(f"Failed to enable TLS: {e}")
            raise SystemExit(1)
    else:
        logger.warning("TLS is disabled; enable use_tls=1 with a CA-signed cert for production.")

    worker_thread = threading.Thread(target=event_worker, daemon=True)
    worker_thread.start()

    scheme = "https" if use_tls else "http"
    logger.info(f"Starting LINE Webhook Server on {scheme}://{bind_address}:{port}")

    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        logger.info("Shutting down server")
    finally:
        httpd.shutdown()
        event_queue.put(None)  # stop worker
        worker_thread.join(timeout=2)


if __name__ == '__main__':
    main()
